{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edfa4c-a30f-4cff-864c-b8d097e96255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gan_artifact_removal.models import UNetGenerator, PatchGANDiscriminator\n",
    "from gan_artifact_removal.dataset import ArtifactDataset\n",
    "from gan_artifact_removal.utils import save_sample\n",
    "from gan_artifact_removal.config import *\n",
    "\n",
    "def train():\n",
    "    dataset = ArtifactDataset(ARTIFACT_DIR, CLEAN_DIR)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    gen = UNetGenerator().to(device)\n",
    "    disc = PatchGANDiscriminator().to(device)\n",
    "\n",
    "    l1_loss = nn.L1Loss()\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    opt_g = torch.optim.Adam(gen.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "    opt_d = torch.optim.Adam(disc.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            fake_y = gen(x)\n",
    "            d_real = disc(x, y)\n",
    "            d_fake = disc(x, fake_y.detach())\n",
    "            loss_d = 0.5 * (bce_loss(d_real, torch.ones_like(d_real)) +\n",
    "                            bce_loss(d_fake, torch.zeros_like(d_fake)))\n",
    "\n",
    "            opt_d.zero_grad()\n",
    "            loss_d.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "            # Train Generator\n",
    "            d_fake = disc(x, fake_y)\n",
    "            loss_g = bce_loss(d_fake, torch.ones_like(d_fake)) + LAMBDA_L1 * l1_loss(fake_y, y)\n",
    "\n",
    "            opt_g.zero_grad()\n",
    "            loss_g.backward()\n",
    "            opt_g.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}/{EPOCHS}] Loss_D: {loss_d.item():.4f} | Loss_G: {loss_g.item():.4f}\")\n",
    "        if (epoch+1) % SAVE_INTERVAL == 0:\n",
    "            save_sample(fake_y, f\"results/gan_epoch_{epoch+1}.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
